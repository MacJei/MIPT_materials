## Передача данных в MPI типа «точка-точка», коллективные операции, управление режимом передачи данных.

Главным действием в MPI-программе, несомненно, является обмен сообщениями между процессами. Рассмотрим способы, которые предоставляет MPI для общения.

* Передача данных типа "точка-точка" — информация пересылается от конкретного узла к другому. Данный тип обмена сообщения происходит посредством двух следующих функций и их соответствующих модификаций:
  * `int MPI_Send(const void *buf, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm)` — осуществляет отправку сообщения на узел с рангом `dest`. При этом сообщения помечаются своим тегом для их дальнейшего разделения на приеме;
  * `int MPI_Recv(void *buf, int count, MPI_Datatype datatype, int source, int tag, MPI_Comm comm, MPI_Status *status)` — производит прием сообщения с тегом `tag` от узла с рангом `source`.

  Функции `MPI_Send` и `MPI_Recv` являются блокирующими: выполнение программы не продолжится до тех пор, пока буфер для отправки не может быть безопасно перезаписан (короче говоря, пока не скопируются данные в трубу для отправки); после операции `MPI_Recv` выполнение продолжается только по факту принятия сообщения.

  По аналогии были добавлены неблокирующие функции для получения и отправки сообщений:
  * `int MPI_Isend(const void *buf, int count, MPI_Datatype datatype, int dest, int tag, MPI_Comm comm, MPI_Request *request)` — производит неблокирующую отправку сообщения;
  * `int MPI_Irecv(void *buf, int count, MPI_Datatype datatype, int source, int tag, MPI_Comm comm, MPI_Request *request)` — производит неблокирующий прием сообщения.

  Как видно из синтаксиса, появляется дополнительный аргумент типа `MPI_Request`, который позволяет отслеживать статус отправки/доставки данных. API MPI предлагает следующие функции ля просмотра состояния передачи информации (или ожидания окончания передачи):
  * `int MPI_Wait(MPI_Request *request, MPI_Status *status)` — ожидает момент выполнения данного запроса на получение / доставку;
  * `int MPI_Test(MPI_Request *request, int *flag, MPI_Status *status)` позволяет проверить, закончилось ли выполнение требуемого запроса (при помощи `flag`);
  * `int MPI_Waitany(int count, MPI_Request array_of_requests[], int *indx, MPI_Status *status)` — позволяет ожидать момента выполнения одного запроса из предложенного набора (возвращается порядковый номер выполненного запроса);
  * `int MPI_Waitall(int count, MPI_Request array_of_requests[], MPI_Status array_of_statuses[])` — позволяет ожидать выполнения всех запросов, если такой процесс возможен (при этом соответствующую информацию можно получить в массиве array_of_statuses);
  * аналогичным образом можно использовать функции `MPI_Testall`, `MPI_Testany`.

* Коллективная передача сообщений — процесс передачи информации задействует группу пользователей, привязанную к данному коммуникатору. При этом все функции, вызываемые при коллективных операциях, носят блокирующий характер: выполнение программы не продолжится до тех пор, пока каждый процесс из группы не вызовет подобную функцию. Перечислим основное API для осуществления таких операций:
  * `int MPI_Barrier(MPI_Comm comm)` — используется для установки барьера на всех процессах группы;
  * `int MPI_Bcast(void *buffer, int count, MPI_Datatype datatype, int root, MPI_Comm comm)` —  предназначена для пересылки определенного сообщения от процесса, ранг которого равен `root`, ко всем остальным процессам, соединенным коммуникатором `comm`, включая и сам `root`;
  * `int MPI_Scatter(const void *sendbuf, int sendcount, MPI_Datatype sendtype, void *recvbuf, int recvcount, MPI_Datatype recvtype, int root, MPI_Comm comm)` —  позволяет отправлять одновременно пакеты сообщений каждому процессу (в отличие от `MPI_Bcast` отдельному процессу отдается свой кусок информации). Каждый процесс в группе может принимать сообщение из аргумента `recvbuf`, а `root` отправляет информацию, расположенную по указателю `sendbuf`;
  * `int MPI_Gather(const void *sendbuf, int sendcount, MPI_Datatype sendtype, void *recvbuf, int recvcount, MPI_Datatype recvtype, int root, MPI_Comm comm)` — обладает обратным эффектом, то есть предназначена для сбора общей информации в выделенном узле, обозначаемом `root`;
  * аналогичным образом определяются функции `MPI_Gatherv` и `MPI_Scatterv`, в которых для каждого процесса отводится не фиксированный размер данных, а заданный пользователем в виде массива смещений (только нужно ввести дополнительные параметры, указывающие, какому процессору какой размер отводится и с каким смещением от начала буфера).

Обсудим, каким образом можно управлять способом передачи данных. MPI предоставляет отправку
данных четырьмя различными способами.

* Стандартный способ — выполняется посредством функции `MPI_Send`. При этом выполнены следующие гарантия:
  * на время выполнения функции процесс-отправитель блокируется;
  * после завершения буфер может быть использован повторно;
  * состояние отправленного сообщения при этом может быть разнообразным (от нахождения в процессе-отправителе до принятия другим
узлом).

* Cинхронный метод — реализуется посредством функции `MPI_Ssend`. Особенность режима: завершение функции отправки сообщения происходит только при подтверждении у принимающей стороны начала приема посылки.

* Буферизованный — выполняется посредством вызова `MPI_Bsend`. Режим предполагает использование дополнительных системных буферов для копирования в них отправляемых сообщений. Конец вызова функции происходит при полном копировании сообщения в системный буфер. Важно при этом понимать, что буфер в этом режиме можно использовать лишь единожды. Для создания буфера используется операция `int MPI_Buffer_attach(void *buffer, int size)`.

  Размер для буфера вычисляется следующим образом: для каждого объекта измеряется объем информации, который он занимает (посредством функции `MPI_Pack_size`); далее к каждому вычисленному размеру прибавляется константа `MPI_BSEND_OVERHEAD`, величина которой равняется объему метаинформации, необходимой для корректной передачи данных; наконец, полученные значения cуммируются. Для разъяснений приведем пример создания необходимого буфера:

  ```C++
  int size1;
  int size2;
  MPI_Pack_size(20, MPI_INT, MPI_COMM_WORLD, &size1);
  MPI_Pack_size(40, MPI_DOUBLE, MPI_COMM_WORLD, &size2);
  int size = size1 + size2 + 2 * MPI_BSEND_OVERHEAD;
  int* buffer = (int*)malloc(size);
  MPI_Buffer_attach(buffer, size);
  // ...
  MPI_Buffer_detach(&buffer, &size);
  ```

  Начиная со стандарта MPI 3.0, появились коллективные неблокирующие операции: `MPI_IBarrier`, `MPI_IBcast` и т. д. Как известно, коллективные операции все являются блокирующими в том смысле, что поток выполнения останавливается, пока все процессы данного коммуникатора не вызовут эту коллективную операцию. Вообще абсолютно на каждую коллективную операцию появилась альтернативная неблокирующая (с добавлением буквы I перед названием операции). Синтаксис остался таким же, как в случае `MPI_ISend` и `MPI_IRecv`. Таким образом, помимо всех стандартных аргументов, добавляется новый аргумент-результат `request`, по которому можно позже сделать `MPI_Wait` и дождаться момента, когда операция действительно закончит свое выполнение.

  Возможностей эти операции добавляют довольно много: можно даже сделать 2 бродкаста, которые будут друг друга обгонять. Использование этих операций может очень сильно повысить эффективность вашего кода, потому что вы получаете доступ к коллективным рассылкам, при этом избегая необходимости в коллективной синхронизации.

* Режим передачи по готовности — реализован при помощи `MPI_Rsend`. В данном режиме передача информации начинается после инициирования операции приема на другой стороне. Как видно, разные режимы передачи данных необходимы для достижения надежности или скорости обмена сообщениями.
