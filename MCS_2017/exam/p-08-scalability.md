## Понятия ускорения и масштабируемости параллельных программ, закон Амдала. Оценка эффективности параллельных программ. Слабая масштабируемость. Сверхлинейная масштабируемость. Оценка накладных расходов на операции ввода-вывода, передачи данных и саму организацию параллелизма.

Пусть есть задание, длина входа которого равна `n`, `p` — число процессоров. Положим `T(p, n)` при `p >= 2` — время работы данной параллельной реализации с данным выбранном способом распалаллеливания на входе длины `n`, использя `p` процессоров, а `T(1, n)` — время работы наилучшей последовательной реализации на данном входе.

Тогда определим ускорение как величину `S(p, n) = T(1, n) / T(p, n)` — во сколько раз быстрее мы решили задачу.

Масштабируемость — величина `K(m, n) = max{p | S(p, n) >= m}`, то есть максимальное число потоков, на котором будет ускорение хотя бы в `m` раз. В реальности график услокрения не линеен. Он всегда ниже идеальной прямой, но сначала он выпуклый вниз, а потом выпуклый вверх и на большом количестве потоков ускорение начинает убывать. Первое связано с тем, что «очень параллельная» программа на небольшом потоке будет тормозить из-за работы механизмов параллелизма, а на большом числе потоков сильно возрастают накладные расходы на передачу данных.

Сформулируем два закона Амдала.
* > Производительность вычислительной системы, состоящей из связанных между собой устройств, в общем случае определяется самым непроизводительным ее устройством.
* > Пусть система состоит из `n` одинаковых простых универсальных устройств, `a` - доля параллельных вычислений, `r` — задержка сети. Тогда максимальное ускорение равно `S = 1 / (1 - a +  a / n + r(a, n))`.

Эффективность — величина `E(p, n) = S(p, n) / p` — насколько времени загружено оборудование (то есть сколько времени процессоры решают непосредственно задачу, а не синхронизируются и не тратят время другие вещи). В теории эффективность всегда не больше 1, и задача состоит в том, что сделать ее к 1 как можно ближе. Иными словами, хотим ускорения `p` на `p` процессорах.

У программы имеет место слабая масштабируемость, когда `max{p | S(p, n) <= m} / max{p | S(cp, cn) <= m} = const`. Иными словами, есть слабая масштабируемость, если после увеличении объема задачи задачи, число процессоров, нужное для того же ускроения, увеличивается пропорционально объему задачи. Это означает, что нет издержек на огранизацию чего-то, связанного с объемом задачи. Если же условие не выполняется, то, например, может понадобиться переписать программу из-за того, что число узлов возросло с 10000 до 50000.

Масштабируемость называется сверхлинейной, если `S(p, n) > p`. Это нарушает закон Амдала, но на самом деле все нормально: это явление вызвано тем, что часть данных была помещена в кеш, что стало возможно из-за конкретной реализации параллелизма.
